{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Validation with Pandera\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/unionai-oss/pandera-workshop/blob/main/workshop.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "In this workshop, we'll learn how to ensure the integrity and reliability of\n",
    "your data with Pandera.\n",
    "\n",
    "We'll cover:\n",
    "- ðŸ¤” Why Data Quality Matters: Understand common data quality challenges and their impact on data-driven applications.\n",
    "- âœ… Introduction to Pandera: Explore the core concepts of Pandera, including schema definitions, checks, and validation strategies.\n",
    "- â­ï¸ Hands-on Demo: Build real-world data validation pipelines to catch errors early and improve the reliability of your datasets.\n",
    "- ðŸ”€ Integrating with Workflows: See how Pandera fits into machine learning pipelines, data engineering workflows, and MLOps environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/unionai-oss/pandera-workshop\n",
    "    %cd pandera-workshop\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## ðŸ¤” Why Data Quality Matters\n",
    "\n",
    "Common data quality challenges:\n",
    "\n",
    "- Data type errors\n",
    "- Out-of-range values\n",
    "- Missing values\n",
    "- Data drift\n",
    "\n",
    "Can lead to:\n",
    "- â±ï¸ Hours debugging data pipelines\n",
    "- ðŸ“‰ Poor model performance\n",
    "- âŒ Incorrect reporting and decision-making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type errors\n",
    "\n",
    "A common data type error is when the column is not the correct type. For example,\n",
    "we might expect a column to be a datetime, but it's actually a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dates = [\"2025-02-01\", \"2025-02-02\", \"2025-02-03\"]\n",
    "dates_df = pd.DataFrame({\"dates\": dates})\n",
    "dates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So certain operations may fail unexpectedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dates_df - pd.Timestamp(\"2025-01-01\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-range values\n",
    "\n",
    "Or columns take on values that are logically impossible, for example, an\n",
    "inventory dataset may contain the price of items, which can't be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = [100, 200, 300, -99999]\n",
    "prices_df = pd.DataFrame({\"prices\": prices})\n",
    "prices_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the average price of items in the inventory may be confusing or misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df[\"prices\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "Long and complex data processing pipelines may lead to missing values, maybe\n",
    "from an incorrectly written SQL query or another bug somewhere in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.DataFrame({\n",
    "    \"price\": [pd.NA, 200000, 300000, 400000, 500000],\n",
    "    \"bedrooms\": [pd.NA, 4, 5, 6, 7],\n",
    "    \"bathrooms\": [2, 3, 4, 5, 6],\n",
    "    \"sqft\": [2000, 3000, 4000, 5000, 6000],\n",
    "})\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases this may be expected due to the inherent nature of the data.\n",
    "\n",
    "However, in cases where missing values are not expected and are due to bugs in\n",
    "data processing code, we would want to catch these early before the cause issues\n",
    "during the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "try:\n",
    "    model = LinearRegression()\n",
    "    model.fit(housing_df[[\"bedrooms\", \"bathrooms\", \"sqft\"]], housing_df[\"price\"])\n",
    "    model.predict(housing_df[[\"bedrooms\", \"bathrooms\", \"sqft\"]])\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data drift\n",
    "\n",
    "One of the thorniest problems in machine learning is data drift, where the\n",
    "distribution of the data changes over time, which can cause the relationship\n",
    "between features and the target to change. This may lead to model degradation\n",
    "over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of two normal distributions of some variable from `t1`\n",
    "drifting to `t2` over time. The `target` is correlated with `data_t1`, but not\n",
    "with `data_t2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate two normal distributions with different parameters\n",
    "n_samples = 1000\n",
    "\n",
    "data_t1 = stats.norm.rvs(loc=0, scale=1, size=n_samples)\n",
    "data_t2 = stats.norm.rvs(loc=2, scale=1.5, size=n_samples)\n",
    "\n",
    "# Create target data that's correlated with data_t1 \n",
    "# Using a linear relationship with some noise\n",
    "target = 2 * data_t1 + stats.norm.rvs(loc=0, scale=0.5, size=n_samples)\n",
    "\n",
    "distributions = pd.DataFrame({\n",
    "    \"data_t1\": data_t1,\n",
    "    \"data_t2\": data_t2,\n",
    "    \"target\": target,\n",
    "})\n",
    "\n",
    "distributions[[\"data_t1\", \"data_t2\"]].plot.hist(bins=50, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "distributions[[\"data_t1\", \"target\"]].plot.scatter(x=\"data_t1\", y=\"target\", ax=ax[0])\n",
    "distributions[[\"data_t2\", \"target\"]].plot.scatter(x=\"data_t2\", y=\"target\", ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Introduction to Pandera\n",
    "\n",
    "Pandera is a tool for validating data in Python. It provides an easy way to\n",
    "define data validation rules in Python and apply them on data at runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a schema for the `housing_df` toy dataset that we created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a schema for just the data types of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera as pa\n",
    "\n",
    "class HousingSchema(pa.DataFrameModel):\n",
    "    price: float\n",
    "    bedrooms: int\n",
    "    bathrooms: float\n",
    "    sqft: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's not all we can do. We can also add value checks to ensure that the\n",
    "values are within a certain range of allowed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingSchema(pa.DataFrameModel):\n",
    "    price: float = pa.Field(ge=50_000)\n",
    "    bedrooms: int = pa.Field(ge=1)\n",
    "    bathrooms: float = pa.Field(ge=1)\n",
    "    sqft: int = pa.Field(ge=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Pandera assumes that missing values are not allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    HousingSchema.validate(housing_df)\n",
    "except pa.errors.SchemaError as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to clean the data to make the validation pass. In this case, let's do\n",
    "the simple thing and remove rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_housing_df = housing_df.dropna()\n",
    "clean_housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can easily create custom validation checks to check for data drift\n",
    "or other statistical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingSchemaWithCorrelation(pa.DataFrameModel):\n",
    "    price: float = pa.Field(ge=50_000)\n",
    "    bedrooms: int = pa.Field(ge=1)\n",
    "    bathrooms: float = pa.Field(ge=1)\n",
    "    sqft: int = pa.Field(ge=100)\n",
    "\n",
    "    @pa.dataframe_check(error=\"price and all other features must be positively correlated\")\n",
    "    def check_price_correlation(cls, df: pd.DataFrame) -> bool:\n",
    "        corr_df = df.corr()\n",
    "        correlated = corr_df[\"price\"].loc[[\"bedrooms\", \"bathrooms\", \"sqft\"]] > 0\n",
    "        return correlated.all()\n",
    "    \n",
    "    class Config:\n",
    "        coerce = True\n",
    "    \n",
    "HousingSchemaWithCorrelation.validate(clean_housing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_housing_df = clean_housing_df.copy()\n",
    "corrupted_housing_df[\"bedrooms\"] = corrupted_housing_df[\"bedrooms\"].tolist()[::-1]\n",
    "\n",
    "try:\n",
    "    HousingSchemaWithCorrelation.validate(corrupted_housing_df)\n",
    "except pa.errors.SchemaError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â­ï¸ Hands-on Demo\n",
    "\n",
    "In this demo, we're going to see try to protect against a common machine learning\n",
    "attack: the label-flipping data poisoning attack.\n",
    "\n",
    "In this attack, an adversary wants to degrade the performance of an ML model by\n",
    "flipping the labels in a tabular dataset. If the adversary isn't careful about\n",
    "how they corrupt the data, we can easily catch this kind of attack against a\n",
    "reference dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_heart_disease_data() -> pd.DataFrame:\n",
    "    heart_disease_data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "    columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
    "    return (\n",
    "        pd.read_csv(heart_disease_data_url, header=None, names=columns)\n",
    "        .replace({\"ca\": {\"?\": None}, \"thal\": {\"?\": None}})\n",
    "        .dropna(subset=[\"ca\", \"thal\"])\n",
    "        .astype({\"ca\": float, \"thal\": float})\n",
    "    )\n",
    "\n",
    "def parse_raw_data(raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert the target to a binary target.\"\"\"\n",
    "    return raw_data.assign(target=lambda _: (_.target > 0).astype(int))\n",
    "\n",
    "\n",
    "heart_disease_df = parse_raw_data(fetch_heart_disease_data())\n",
    "heart_disease_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_data(\n",
    "    df: pd.DataFrame,\n",
    "    poison_fraction: float = 0.0,\n",
    "    random_state: int = 0,\n",
    ") -> pd.DataFrame:\n",
    "    if poison_fraction <= 0.0:\n",
    "        return df\n",
    "    poisoned = df.copy()\n",
    "    n_poison = int(len(poisoned) * poison_fraction)\n",
    "    poisoned_indices = poisoned.sample(n=n_poison, random_state=random_state).index\n",
    "    poisoned.loc[poisoned_indices, 'target'] = 1 - poisoned.loc[poisoned_indices, 'target']\n",
    "    return poisoned\n",
    "\n",
    "poisoned_heart_disease_df = poison_data(heart_disease_df, poison_fraction=0.75)\n",
    "poisoned_heart_disease_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df.target.rename(\"original target\").value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_heart_disease_df.target.rename(\"poisoned target\").value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportions of the target are now different. But are there other ways we\n",
    "can detect that the data has been poisoned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def split_data(parsed_data, test_size: float, random_state: int):\n",
    "    print(\"splitting data\")\n",
    "    training_set = parsed_data.sample(frac=test_size, random_state=random_state)\n",
    "    test_set = parsed_data[~parsed_data.index.isin(training_set.index)]\n",
    "    return training_set, test_set\n",
    "\n",
    "def get_features_and_target(dataset):\n",
    "    X = dataset[[x for x in dataset if x != \"target\"]]\n",
    "    y = dataset[\"target\"]\n",
    "    return X, y\n",
    "\n",
    "def train_model(training_set, random_state: int):\n",
    "    print(\"training model\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    X, y = get_features_and_target(training_set)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def training_pipeline(dataset, test_size: float, random_state: int):\n",
    "    training_set, test_set = split_data(dataset, test_size, random_state)\n",
    "    model = train_model(training_set, random_state)\n",
    "    test_features, test_target = get_features_and_target(test_set)\n",
    "    acc = (model.predict(test_features) == test_target).mean()\n",
    "    return model, acc\n",
    "\n",
    "model, acc = training_pipeline(heart_disease_df, 0.75, 42)\n",
    "print(f\"Test accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, acc = training_pipeline(poisoned_heart_disease_df, 0.75, 42)\n",
    "print(f\"Test accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy of the model trained on the poisoned dataset is now much lower\n",
    "than the one trained on the original dataset.\n",
    "\n",
    "Is there a way to detect that the data has been poisoned even before training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pandera DataFrameModels\n",
    "\n",
    "As we say earlier, `pandera.DataFrameModel` is a way to define a schema\n",
    "declaratively, in much the same way you could define a dataclass or `pydantic`\n",
    "model.\n",
    "\n",
    "Let's create a schema for the raw data that we can use to validate the data\n",
    "before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawData(pa.DataFrameModel):\n",
    "    age: int = pa.Field(in_range={\"min_value\": 0, \"max_value\": 200})\n",
    "    sex: int = pa.Field(isin=[0, 1])\n",
    "    cp: int = pa.Field(\n",
    "        isin=[\n",
    "            1,  # typical angina\n",
    "            2,  # atypical angina\n",
    "            3,  # non-anginal pain\n",
    "            4,  # asymptomatic\n",
    "        ]\n",
    "    )\n",
    "    trestbps: int = pa.Field(in_range={\"min_value\": 0, \"max_value\": 200})\n",
    "    chol: int = pa.Field(in_range={\"min_value\": 0, \"max_value\": 600})\n",
    "    fbs: int = pa.Field(isin=[0, 1])\n",
    "    restecg: int = pa.Field(\n",
    "        isin=[\n",
    "            0,  # normal\n",
    "            1,  # having ST-T wave abnormality\n",
    "            2,  # showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "        ]\n",
    "    )\n",
    "    thalach: int = pa.Field(in_range={\"min_value\": 0, \"max_value\": 300})\n",
    "    exang: int = pa.Field(isin=[0, 1])\n",
    "    oldpeak: float = pa.Field(in_range={\"min_value\": 0, \"max_value\": 10})\n",
    "    slope: int = pa.Field(\n",
    "        isin=[\n",
    "            1,  # upsloping\n",
    "            2,  # flat\n",
    "            3,  # downsloping\n",
    "        ]\n",
    "    )\n",
    "    ca: int = pa.Field(isin=[0, 1, 2, 3])\n",
    "    thal: int = pa.Field(\n",
    "        isin=[\n",
    "            3,  # normal\n",
    "            6,  # fixed defect\n",
    "            7,  # reversible defect\n",
    "        ]\n",
    "    )\n",
    "    target: int = pa.Field(ge=0, le=4)\n",
    "\n",
    "    class Config:\n",
    "        coerce = True\n",
    "        strict = \"filter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inherit from `RawData` to create a schema for the parsed data to make\n",
    "sure that we've binarized the `target` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParsedData(RawData):\n",
    "    target: int = pa.Field(isin=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a `TrainingData` model to validate the statistical properties\n",
    "of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingData(ParsedData):\n",
    "    @pa.dataframe_check(error=\"Patients with heart disease should have higher average cholesterol\")\n",
    "    def validate_cholesterol(cls, df: pd.DataFrame) -> bool:\n",
    "        healthy_chol = df[df.target == 0].chol.mean()\n",
    "        disease_chol = df[df.target == 1].chol.mean()\n",
    "        return disease_chol > healthy_chol\n",
    "\n",
    "    @pa.dataframe_check(error=\"Patients with heart disease should not have lower max heart rate (thalach) on average\")\n",
    "    def validate_max_heart_rate(cls, df: pd.DataFrame) -> bool:\n",
    "        healthy_thalach = df[df.target == 0].thalach.mean()\n",
    "        disease_thalach = df[df.target == 1].thalach.mean()\n",
    "        return disease_thalach < healthy_thalach\n",
    "\n",
    "    @pa.dataframe_check(error=\"Exercise-induced angina is not more common in disease group\")\n",
    "    def validate_exercise_induced_angina(cls, df: pd.DataFrame) -> bool:\n",
    "        exang_ratio = df[df.target == 1].exang.mean() / df[df.target == 0].exang.mean()\n",
    "        return exang_ratio > 2.0\n",
    "\n",
    "    @pa.dataframe_check(error=\"cp, exang, and oldpeak should be positively correlated with target\")\n",
    "    def validate_feature_correlations(cls, df: pd.DataFrame) -> bool:\n",
    "        \"\"\"Ensure key feature correlations with target remain strong\"\"\"\n",
    "        corrs = df.corr()['target']\n",
    "        return bool((corrs[['cp', 'exang', 'oldpeak']] > 0.2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData.validate(heart_disease_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    TrainingData.validate(poisoned_heart_disease_df, lazy=True)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's refactor our pipeline to use the `DataFrameModel`s throughout so\n",
    "we validate the data at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pandera.typing import DataFrame\n",
    "\n",
    "\n",
    "DataSplits = typing.NamedTuple(\n",
    "    \"DataSplits\",\n",
    "    training_set=DataFrame[ParsedData],\n",
    "    test_set=DataFrame[ParsedData],\n",
    ")\n",
    "\n",
    "\n",
    "@pa.check_types(lazy=True)\n",
    "def parse_raw_data(raw_data: DataFrame[RawData]) -> DataFrame[ParsedData]:\n",
    "    \"\"\"Convert the target to a binary target.\"\"\"\n",
    "    print(\"parsing raw data\")\n",
    "    return raw_data.assign(target=lambda _: (_.target > 0).astype(int))\n",
    "\n",
    "@pa.check_types(lazy=True)\n",
    "def split_data(\n",
    "    parsed_data: DataFrame[ParsedData],\n",
    "    test_size: float,\n",
    "    random_state: int,\n",
    ") -> DataSplits:\n",
    "    print(\"splitting data\")\n",
    "    training_set = parsed_data.sample(frac=test_size, random_state=random_state)\n",
    "    test_set = parsed_data[~parsed_data.index.isin(training_set.index)]\n",
    "    return training_set, test_set\n",
    "\n",
    "def get_features_and_target(dataset):\n",
    "    X = dataset[[x for x in dataset if x != \"target\"]]\n",
    "    y = dataset[\"target\"]\n",
    "    return X, y\n",
    "\n",
    "@pa.check_types(lazy=True)\n",
    "def train_model(training_set: DataFrame[TrainingData], random_state: int):\n",
    "    print(\"training model\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    X, y = get_features_and_target(training_set)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_set):\n",
    "    test_features, test_target = get_features_and_target(test_set)\n",
    "    acc = (model.predict(test_features) == test_target).mean()\n",
    "    return acc\n",
    "\n",
    "def training_pipeline(dataset, test_size: float=0.2, random_state: int = 100):\n",
    "    parsed_data = parse_raw_data(dataset)\n",
    "    training_set, test_set = split_data(parsed_data, test_size, random_state)\n",
    "    model = train_model(training_set, random_state)\n",
    "    acc = evaluate_model(model, test_set)\n",
    "    return model, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the pipeline on the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, acc = training_pipeline(heart_disease_df)\n",
    "print(f\"Test accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's run the pipeline on the poisoned dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    training_pipeline(poisoned_heart_disease_df)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”€ Integrating with Workflows\n",
    "\n",
    "In this final section, we'll see how Pandera can be integrated into a machine\n",
    "learning orchestrator.\n",
    "\n",
    "Let's adapt the label-flipping attack demo to a Union workflow, see how\n",
    "we can catch the attack early, and visualize the error report on the Union UI.\n",
    "\n",
    "Take a look at the [`workflow.py`](./workflow.py) file in this repository to see how we can convert\n",
    "the python functions above into a production-ready Union workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the datasetes out into a parquet file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_df.to_parquet(\"heart_disease_df.parquet\")\n",
    "poisoned_heart_disease_df.to_parquet(\"poisoned_heart_disease_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, authenticate with Union:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union create login --auth device-flow --serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `union` CLI to run the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union run --remote workflow.py training_pipeline --dataset heart_disease_df.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run in with the poisoned dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union run --remote workflow.py training_pipeline --dataset poisoned_heart_disease_df.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a `Deck` that visualizes the Panderavalidations that passed and failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ‰ Congrats! You've learned how to use Pandera to validate data at runtime and\n",
    "and integrate it with a machine learning orchestrator to catch data errors and\n",
    "bugs as early as possible so that you can:\n",
    "\n",
    "- Spend less time trying to find where data errors were introduced.\n",
    "- Spend more time focusing on improving your model and data products.\n",
    "\n",
    "To learn more about Union, data validation, and building AI pipelines:\n",
    "\n",
    "- Check out the [Pandera Documentation](https://pandera.readthedocs.io/en/latest/).\n",
    "- Check out the [Union Documentation](https://docs.union.ai/serverless/user-guide/).\n",
    "- Contact us at [Union.ai](https://www.union.ai/contact) for a demo or to learn more about Union Enterprise.\n",
    "- Join our [Slack community](https://join.slack.com/t/flyte-org/shared_invite/zt-1citnqimc-A8NuS9b0qFiqn_yrRCaxtQ) to ask questions and share your projects with other Union users.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandera-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
